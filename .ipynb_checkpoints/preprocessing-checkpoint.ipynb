{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5d6140b-8c8f-4a96-9c4e-a746d036f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25361581-32fd-4de2-a092-330b7d33e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_xml_file(fp: str) -> tuple[str, list[dict[str, str]], list[dict[str, str]], list[dict[str, str]]]:\n",
    "    \"\"\" returns name, text, mentions, and final reactions (labels) for a drug's XML file passed in as fp\"\"\"\n",
    "    root = ET.parse(fp).getroot()\n",
    "    texts = [{\"text\": tt.text,\n",
    "              \"section\": tt.get(\"id\")} for tt in root.findall(\"./Text/Section\")]\n",
    "    mentions = [{\"str\": tt.get(\"str\"), \n",
    "                 \"section\": tt.get(\"section\"),\n",
    "                 \"type\": tt.get(\"type\"),\n",
    "                 \"len\": tt.get(\"len\")} for tt in root.findall(\"./Mentions/Mention\")]\n",
    "    \n",
    "    reactions = list()\n",
    "    for tag_type in root.findall(\"./Reactions/Reaction\"):\n",
    "        norm = tag_type.find(\"Normalization\")\n",
    "        reactions.append(\n",
    "            {\n",
    "                \"name\": tag_type.get(\"str\"),\n",
    "                \"id\": norm.get(\"id\"),\n",
    "                \"meddra_pt\": norm.get(\"meddra_pt\"),\n",
    "                \"meddra_pt_id\": norm.get(\"meddra_pt_id\")\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    return root.get(\"drug\"), texts, mentions, reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "196bbcb2-58d3-48e8-abc8-9c717727034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, texts, mentions, reactions = parse_xml_file(f\"data/tac_2017/train/ADCETRIS.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "19c2108e-5bd6-4905-8b3e-4d6feffb6813",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(texts: list[dict[str, str]]) -> list[dict[str, list[list[str]]]]:\n",
    "    \"\"\" convert each text into a list of lists of sentences -> words\"\"\"\n",
    "    result = []\n",
    "    for section in texts:\n",
    "        cleaned_section = {\"section\": section[\"section\"], \"sentences\": []}\n",
    "        sentences = []\n",
    "        for line in section[\"text\"].split(\"\\n\"):\n",
    "            if len(line)>2:\n",
    "                cleaned_section[\"sentences\"].append(\n",
    "                    [word for word in line.split() if word != \"\"]\n",
    "                )\n",
    "\n",
    "        result.append(cleaned_section)\n",
    "            \n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b745133c-66a1-4a1f-bf64-31c51b4a6c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_texts = clean_text(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "edf8103c-d128-4ada-96f0-0d8e221cc4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_iob_map(texts, mentions):\n",
    "\n",
    "    full_text, tags = [], []\n",
    "    # looping through each section\n",
    "    for i, section in enumerate(texts):\n",
    "\n",
    "        # get all mentions in the current section\n",
    "        idx = f\"S{i+1}\"\n",
    "        relevant_mentions = {m[\"str\"]: m[\"type\"] for m in mentions if m[\"section\"]==idx}\n",
    "\n",
    "        for term, type in relevant_mentions.items():\n",
    "            full_types = []\n",
    "            for i, word in enumerate(term.split()):\n",
    "                if i==0:\n",
    "                    full_types.append(f\"B-{type}\")\n",
    "                else:\n",
    "                    full_types.append(f\"I-{type}\")\n",
    "\n",
    "            relevant_mentions[term] = \" \".join(full_types)\n",
    "        \n",
    "        # loop through each mention, and for that mention, tag the word as B-TYPE, I-TYPE, etc\n",
    "        for line in section[\"sentences\"]:\n",
    "            full_line = \" \".join(line)\n",
    "            tag_line = full_line\n",
    "            for term, type in relevant_mentions.items():\n",
    "                #tag_line = tag_line.replace(term, type)\n",
    "\n",
    "                pattern = f\"{ term.replace(\"-\", \"\\-\") }[ .,;:]\"\n",
    "                print(pattern)\n",
    "                repl = f\"{ type.replace(\"-\", \"\\-\") }[ ,;:]\"\n",
    "                \n",
    "                # replace \n",
    "                tag_line = re.sub(pattern=pattern, repl=repl, string=tag_line) # tag_line.replace(term+\" \", type+\" \")\n",
    "\n",
    "            # print(\"***********************\")\n",
    "            # print(full_line)\n",
    "            # print(tag_line)\n",
    "            # print(\"***********************\")\n",
    "            full_text.append(full_line.split())\n",
    "            tags.append(tag_line.split())\n",
    "\n",
    "    for i in range(len(tags)):\n",
    "        for j in range(len(tags[i])):\n",
    "            if not tags[i][j].startswith((\"B-\", \"I-\")):\n",
    "                tags[i][j] = \"O\"\n",
    "            \n",
    "    # we want to return a full concatenated text, and a full list of tags, one tag for each word in the text\n",
    "    return full_text, tags\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a38c2edf-ec33-4d69-956e-777cf18dc927",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft, tags = build_iob_map(cleaned_texts, mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "23b7d3b0-0ff0-472a-9b3b-b02425aa13c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ner_get_preprocessed_data(dataset=\"train\"):\n",
    "    \"\"\" returns X, Y for training set \"\"\"\n",
    "    \n",
    "    files = os.listdir(f\"data/tac_2017/{dataset}/\")\n",
    "    sentset = []\n",
    "    tagset = []\n",
    "    \n",
    "    for fp in files:\n",
    "        _, texts, mentions, _ = parse_xml_file(f\"data/tac_2017/{dataset}/{fp}\")\n",
    "        cleaned_texts = clean_text(texts)\n",
    "        full_text, tags = build_iob_map(cleaned_texts, mentions)\n",
    "        sentset.extend(full_text)\n",
    "        tagset.extend(tags)\n",
    "    \n",
    "    return sentset, tagset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "54a43baa-be27-469a-a505-d33c5e8c9471",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentset, tagset = ner_get_preprocessed_data(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0f1473fc-ddf6-42ab-a1e2-16032853dd63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10353"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c0931626-7467-47cd-9668-f62a61174a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10353"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tagset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b24181-f3ad-448f-a7a8-fab880af43b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
